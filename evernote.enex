<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE en-export SYSTEM "http://xml.evernote.com/pub/evernote-export3.dtd">
<en-export export-date="20181015T055220Z" application="Evernote" version="Evernote Mac 7.0.3 (456407)">
<note><title>ByteCup</title><content><![CDATA[<!DOCTYPE en-note SYSTEM "http://xml.evernote.com/pub/enml2.dtd"><en-note><div><div>整个项目都将基于encoder-decoder的架构，并且会加入attention。</div><div><br /></div><div>最简单的Baseline:</div><div>取开头的若干个句子</div><div><br /></div><hr /><div><b>模型结构：</b></div><div><br /></div><div><en-todo checked="false" />Baseline1</div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>encoder </div><div>基于RNN的encoder，只输出一个context vector</div><div><br /></div><div>decoder</div><div>在每一个time-step输出一个维度为V的向量，每一个维度代表某个单词的概率 （V大小限定为3W，其余词均为UNK）</div><div><br /></div><div>predict时RNN decode使用greedy策略</div></div><div><br /></div><div><en-todo checked="false" />+ 使用双向RNN做encoding</div><div><br /></div><div><en-todo checked="true" />+ attention<br /></div><div><a href="https://arxiv.org/abs/1509.00685">https://arxiv.org/abs/1509.00685</a></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div><span style="font-family: Monaco; font-size: 9pt; color: rgb(51, 51, 51);">[*]</span>对source加入attention, </div><div><span style="font-family: Monaco; font-size: 9pt; color: rgb(51, 51, 51);">[ ]</span>对target也可以加入attention（self-attention？）</div><div>[ ]几种不同score函数的选用 (dot-product等)<br /></div></div><div><br /></div><div><en-todo checked="false" />+ RNN viterbi or beam search (predict decoding 的时候)</div><div><br /></div><div><en-todo checked="false" />+ 使用简单的language model来解决UNK的问题</div><div><br /></div><div><en-todo checked="false" />+ pointer generator<br /></div><div><a href="https://arxiv.org/abs/1808.01426">https://arxiv.org/abs/1808.01426</a></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>主要是为了解决UNK的问题，有时候可以直接从原文中拷贝。</div><div><br /></div><div>1. 计算是否拷贝的函数的输入</div></div><hr /><div><br /></div><div><en-todo checked="false" />+ convergence <br /></div><div><a href="https://arxiv.org/abs/1808.01426">https://arxiv.org/abs/1808.01426</a></div><div><a href="https://arxiv.org/abs/1601.04811">https://arxiv.org/abs/1601.04811</a></div><div style="box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902);-en-codeblock:true;"><div>解决同一个source的hj被多次使用的问题</div></div><div><br /></div><div><en-todo checked="false" />+ source, target input 和 target output 共享embedding 层， output的W矩阵做投影。</div><div><br /></div><div><en-todo checked="false" />+ 扩展输入，提取文章中的重要词句，然后做第二个encoder，重要句子的问题可以参考lesk algorithm</div><div><br /></div><div><en-todo checked="false" />尝试使用CNN做encoder  decoder feature map的提取<br /></div><div><ul><li><a href="https://arxiv.org/abs/1705.03122">https://arxiv.org/abs/1705.03122</a></li></ul></div><div><en-todo checked="false" /> 增加attention可视化模块<br /></div><div><en-todo checked="false" />encoder的输入使用预训练embedding或加入embedding层，或两者都用</div><div><br /></div><div><hr /></div><div></div><div><b>数据预处理：</b></div><div><br /></div><div><en-todo checked="false" />将文本通过nltk分词器分词</div><div><en-todo checked="false" />将所有单词转换为小写</div><div><en-todo checked="false" />去掉大部分单词周围的引号</div><div><en-todo checked="false" />lemmazation</div><div><en-todo checked="false" />stemming</div><div><en-todo checked="false" />去掉部分标点符号</div><div><br /></div><div><hr /></div><div><b>其他相关Paper</b></div><div><b><br /></b></div>Teacher Forcing相关的Paper</div><div><ul><li><a href="https://arxiv.org/abs/1506.03099"><font style="font-size: 14px;" face="Helvetica Neue" color="#000000">https://arxiv.org/abs/1506.03099</font></a><br /></li><li><a href="https://arxiv.org/abs/1610.09038"><font style="font-size: 14px;" face="Helvetica Neue" color="#000000">https://arxiv.org/abs/1610.09038</font></a><br /></li></ul><div></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div></div><div><br /></div></en-note>]]></content><created>20180928T132716Z</created><updated>20181014T054324Z</updated><note-attributes><author>pppjjjsss@126.com</author><source>desktop.win</source><source-url>https://www.google.com/search?ei=Xy6uW4jcF-T19AO7iYygDg&amp;q=lesk+algormthim+&amp;oq=lesk+algormthim+&amp;gs_l=psy-ab.12..0i13j0i13i30l2j0i13i5i30.408983.408983..409505...0.0..0.315.315.3-1......0....1j2..gws-wiz.......0i71.5y6rbpjAqtE</source-url><source-application>evernote.win32</source-application><reminder-order>0</reminder-order></note-attributes></note>
</en-export>
